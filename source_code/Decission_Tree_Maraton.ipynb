{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jK9tCTcwqq4k"
      },
      "source": [
        "## Installing TensorFlow Decision Forests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pa1Pf37RhEYN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe30ddad-09a2-4746-da7c-4d45cabec160"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow_decision_forests in /usr/local/lib/python3.10/dist-packages (1.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.5.3)\n",
            "Requirement already satisfied: tensorflow~=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (2.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.16.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.4.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (0.42.0)\n",
            "Requirement already satisfied: wurlitzer in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (3.0.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (67.7.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (1.60.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (2.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow_decision_forests) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow_decision_forests) (2023.3.post1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_decision_forests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oinwbhXlggd"
      },
      "source": [
        "## Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52W45tmDjD64"
      },
      "outputs": [],
      "source": [
        "import tensorflow_decision_forests as tfdf\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import math\n",
        "tf.random.set_seed(8395337)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qsSU1RfmNiP"
      },
      "source": [
        "### Load the dataset and convert it in a tf.Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "family_data=pd.read_csv('./Metadata_and_relative_abundance_of_seminal_microbiota_from_idiopathic_infertile_patients_and_donors.xlsx - Family-level microbiota.csv', na_values=['#DIV/0!'])\n",
        "genus_data=pd.read_csv('./Metadata_and_relative_abundance_of_seminal_microbiota_from_idiopathic_infertile_patients_and_donors.xlsx - Genus-level microbiota.csv', na_values=['#DIV/0!'])\n",
        "phylum_data=pd.read_csv('./Metadata_and_relative_abundance_of_seminal_microbiota_from_idiopathic_infertile_patients_and_donors.xlsx - Pylum-level microbiota.csv', na_values=['#DIV/0!'])\n",
        "metadata=pd.read_csv('./Metadata_and_relative_abundance_of_seminal_microbiota_from_idiopathic_infertile_patients_and_donors.xlsx - Sample info + Sperm quality.csv', na_values=['#DIV/0!'])\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.options.display.max_columns = None\n",
        "pd.options.display.max_rows = None"
      ],
      "metadata": {
        "id": "QMXCWqLQQifQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadata_phylum_relation = pd.merge(metadata[['Sample ID', 'Clinical status']],phylum_data , on = 'Sample ID' , how = 'inner')\n",
        "metadata_family_relation = pd.merge(metadata[['Sample ID', 'Clinical status']],family_data , on = 'Sample ID' , how = 'inner')\n",
        "metadata_genus_relation = pd.merge(metadata[['Sample ID', 'Clinical status']],genus_data , on = 'Sample ID' , how = 'inner')"
      ],
      "metadata": {
        "id": "wDFkvjYjRMph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadata_phylum_relation['Clinical status'] = metadata_phylum_relation.get('Clinical status').apply(lambda x: 0 if x == 'Infertile' else 1)\n",
        "metadata_family_relation['Clinical status'] = metadata_family_relation.get('Clinical status').apply(lambda x: 0 if x == 'Infertile' else 1)\n",
        "metadata_genus_relation['Clinical status'] = metadata_genus_relation.get('Clinical status').apply(lambda x: 0 if x == 'Infertile' else 1)\n"
      ],
      "metadata": {
        "id": "CAjQf9OmSxrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadata_phylum_relation.drop('Sample ID', axis=1, inplace=True)\n",
        "metadata_family_relation.drop('Sample ID', axis=1, inplace=True)\n",
        "metadata_genus_relation.drop('Sample ID', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "Nh_5cbz-eSlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = metadata_phylum_relation"
      ],
      "metadata": {
        "id": "iCjl8-jAxXTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7DEIxn2oB3U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15066d0b-e118-44ab-86da-5498799d82e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48 examples in training, 8 examples for testing.\n"
          ]
        }
      ],
      "source": [
        "# Split the dataset into a training and a testing dataset.\n",
        "DO_EVAL = True\n",
        "\n",
        "def split_dataset(dataset, test_ratio=0.15):\n",
        "  \"\"\"Splits a panda dataframe in two.\"\"\"\n",
        "  test_indices = np.random.rand(len(dataset)) < test_ratio\n",
        "  return dataset[~test_indices], dataset[test_indices]\n",
        "\n",
        "if DO_EVAL:\n",
        "  train_ds_pd, test_ds_pd = split_dataset(dataset)\n",
        "  print(\"{} examples in training, {} examples for testing.\".format(\n",
        "      len(train_ds_pd), len(test_ds_pd)))\n",
        "else:\n",
        "  train_ds_pd = dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWq7uQcCuBzO"
      },
      "source": [
        "And finally, convert the pandas dataframe (`pd.Dataframe`) into tensorflow datasets (`tf.data.Dataset`):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtXgUBKluTX0"
      },
      "outputs": [],
      "source": [
        "label = \"Clinical status\"\n",
        "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=label, fix_feature_names=False)\n",
        "if DO_EVAL:\n",
        "  test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_ds_pd, label=label, fix_feature_names=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYAoyfYtqHG4"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xete-FbuqJCV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fff4b68-fcfc-4b77-c4ef-b806b2b91d9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use 2 thread(s) for training\n",
            "Use /tmp/tmptcmxye7a as temporary training directory\n",
            "Reading training dataset...\n",
            "Training tensor examples:\n",
            "Features: {'Firmicutes': <tf.Tensor 'data:0' shape=(None,) dtype=float64>, 'Proteobacteria': <tf.Tensor 'data_1:0' shape=(None,) dtype=float64>, 'Actinobacteria': <tf.Tensor 'data_2:0' shape=(None,) dtype=float64>, 'Tenericutes': <tf.Tensor 'data_3:0' shape=(None,) dtype=float64>, 'Bacteroidetes': <tf.Tensor 'data_4:0' shape=(None,) dtype=float64>, 'Armatimonadetes': <tf.Tensor 'data_5:0' shape=(None,) dtype=float64>, 'Spirochaetes': <tf.Tensor 'data_6:0' shape=(None,) dtype=float64>, 'Planctomycetes': <tf.Tensor 'data_7:0' shape=(None,) dtype=float64>, 'Verrucomicrobia': <tf.Tensor 'data_8:0' shape=(None,) dtype=float64>, 'Chloroflexi': <tf.Tensor 'data_9:0' shape=(None,) dtype=float64>, 'Chrysiogenetes': <tf.Tensor 'data_10:0' shape=(None,) dtype=float64>, 'Aquificae': <tf.Tensor 'data_11:0' shape=(None,) dtype=float64>, 'Fusobacteria': <tf.Tensor 'data_12:0' shape=(None,) dtype=float64>, 'Chlorobi': <tf.Tensor 'data_13:0' shape=(None,) dtype=float64>, 'Gemmatimonadetes': <tf.Tensor 'data_14:0' shape=(None,) dtype=float64>, 'Synergistetes': <tf.Tensor 'data_15:0' shape=(None,) dtype=float64>, 'Thermotogae': <tf.Tensor 'data_16:0' shape=(None,) dtype=float64>, 'Candidatus.Bipolaricaulota': <tf.Tensor 'data_17:0' shape=(None,) dtype=float64>, 'Candidatus.Saccharibacteria': <tf.Tensor 'data_18:0' shape=(None,) dtype=float64>, 'Deinococcus.Thermus': <tf.Tensor 'data_19:0' shape=(None,) dtype=float64>, 'Cyanobacteria': <tf.Tensor 'data_20:0' shape=(None,) dtype=float64>, 'Deferribacteres': <tf.Tensor 'data_21:0' shape=(None,) dtype=float64>, 'Dictyoglomi': <tf.Tensor 'data_22:0' shape=(None,) dtype=float64>, 'Balneolaeota': <tf.Tensor 'data_23:0' shape=(None,) dtype=float64>, 'Fibrobacteres': <tf.Tensor 'data_24:0' shape=(None,) dtype=float64>, 'Chlamydiae': <tf.Tensor 'data_25:0' shape=(None,) dtype=float64>, 'Acidobacteria': <tf.Tensor 'data_26:0' shape=(None,) dtype=float64>, 'Kiritimatiellaeota': <tf.Tensor 'data_27:0' shape=(None,) dtype=float64>, 'Nitrospirae': <tf.Tensor 'data_28:0' shape=(None,) dtype=float64>, 'candidate.division.Zixibacteria': <tf.Tensor 'data_29:0' shape=(None,) dtype=float64>, 'Thermodesulfobacteria': <tf.Tensor 'data_30:0' shape=(None,) dtype=float64>}\n",
            "Label: Tensor(\"data_31:0\", shape=(None,), dtype=int64)\n",
            "Weights: None\n",
            "Normalized tensor features:\n",
            " {'Firmicutes': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast:0' shape=(None,) dtype=float32>), 'Proteobacteria': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_1:0' shape=(None,) dtype=float32>), 'Actinobacteria': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_2:0' shape=(None,) dtype=float32>), 'Tenericutes': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_3:0' shape=(None,) dtype=float32>), 'Bacteroidetes': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_4:0' shape=(None,) dtype=float32>), 'Armatimonadetes': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_5:0' shape=(None,) dtype=float32>), 'Spirochaetes': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_6:0' shape=(None,) dtype=float32>), 'Planctomycetes': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_7:0' shape=(None,) dtype=float32>), 'Verrucomicrobia': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_8:0' shape=(None,) dtype=float32>), 'Chloroflexi': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_9:0' shape=(None,) dtype=float32>), 'Chrysiogenetes': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_10:0' shape=(None,) dtype=float32>), 'Aquificae': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_11:0' shape=(None,) dtype=float32>), 'Fusobacteria': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_12:0' shape=(None,) dtype=float32>), 'Chlorobi': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_13:0' shape=(None,) dtype=float32>), 'Gemmatimonadetes': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_14:0' shape=(None,) dtype=float32>), 'Synergistetes': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_15:0' shape=(None,) dtype=float32>), 'Thermotogae': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_16:0' shape=(None,) dtype=float32>), 'Candidatus.Bipolaricaulota': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_17:0' shape=(None,) dtype=float32>), 'Candidatus.Saccharibacteria': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_18:0' shape=(None,) dtype=float32>), 'Deinococcus.Thermus': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_19:0' shape=(None,) dtype=float32>), 'Cyanobacteria': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_20:0' shape=(None,) dtype=float32>), 'Deferribacteres': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_21:0' shape=(None,) dtype=float32>), 'Dictyoglomi': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_22:0' shape=(None,) dtype=float32>), 'Balneolaeota': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_23:0' shape=(None,) dtype=float32>), 'Fibrobacteres': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_24:0' shape=(None,) dtype=float32>), 'Chlamydiae': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_25:0' shape=(None,) dtype=float32>), 'Acidobacteria': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_26:0' shape=(None,) dtype=float32>), 'Kiritimatiellaeota': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_27:0' shape=(None,) dtype=float32>), 'Nitrospirae': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_28:0' shape=(None,) dtype=float32>), 'candidate.division.Zixibacteria': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_29:0' shape=(None,) dtype=float32>), 'Thermodesulfobacteria': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_30:0' shape=(None,) dtype=float32>)}\n",
            "Training dataset read in 0:00:06.965546. Found 48 examples.\n",
            "Training model...\n",
            "Standard output detected as not visible to the user e.g. running in a notebook. Creating a training log redirection. If training gets stuck, try calling tfdf.keras.set_training_logs_redirection(False).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[INFO 23-12-16 19:50:00.1681 UTC kernel.cc:771] Start Yggdrasil model training\n",
            "[INFO 23-12-16 19:50:00.1682 UTC kernel.cc:772] Collect training examples\n",
            "[INFO 23-12-16 19:50:00.1682 UTC kernel.cc:785] Dataspec guide:\n",
            "column_guides {\n",
            "  column_name_pattern: \"^__LABEL$\"\n",
            "  type: CATEGORICAL\n",
            "  categorial {\n",
            "    min_vocab_frequency: 0\n",
            "    max_vocab_count: -1\n",
            "  }\n",
            "}\n",
            "default_column_guide {\n",
            "  categorial {\n",
            "    max_vocab_count: 2000\n",
            "  }\n",
            "  discretized_numerical {\n",
            "    maximum_num_bins: 255\n",
            "  }\n",
            "}\n",
            "ignore_columns_without_guides: false\n",
            "detect_numerical_as_discretized_numerical: false\n",
            "\n",
            "[INFO 23-12-16 19:50:00.1688 UTC kernel.cc:391] Number of batches: 1\n",
            "[INFO 23-12-16 19:50:00.1688 UTC kernel.cc:392] Number of examples: 48\n",
            "[INFO 23-12-16 19:50:00.1689 UTC kernel.cc:792] Training dataset:\n",
            "Number of records: 48\n",
            "Number of columns: 32\n",
            "\n",
            "Number of columns by type:\n",
            "\tNUMERICAL: 31 (96.875%)\n",
            "\tCATEGORICAL: 1 (3.125%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "NUMERICAL: 31 (96.875%)\n",
            "\t0: \"Acidobacteria\" NUMERICAL mean:0.0107396 min:0 max:0.3866 sd:0.0569299\n",
            "\t1: \"Actinobacteria\" NUMERICAL mean:7.72069 min:0.1785 max:33.2099 sd:6.63594\n",
            "\t2: \"Aquificae\" NUMERICAL mean:0.00205833 min:0 max:0.0274 sd:0.0042918\n",
            "\t3: \"Armatimonadetes\" NUMERICAL mean:0.0403438 min:0 max:0.2398 sd:0.0464239\n",
            "\t4: \"Bacteroidetes\" NUMERICAL mean:6.01432 min:0.0161 max:27.5289 sd:8.19502\n",
            "\t5: \"Balneolaeota\" NUMERICAL mean:0.000427083 min:0 max:0.006 sd:0.00108219\n",
            "\t6: \"Candidatus.Bipolaricaulota\" NUMERICAL mean:0.000560417 min:0 max:0.0055 sd:0.0012734\n",
            "\t7: \"Candidatus.Saccharibacteria\" NUMERICAL mean:0.0634771 min:0 max:1.7215 sd:0.257126\n",
            "\t8: \"Chlamydiae\" NUMERICAL mean:0.00274792 min:0 max:0.0407 sd:0.00789354\n",
            "\t9: \"Chlorobi\" NUMERICAL mean:0.00253958 min:0 max:0.0262 sd:0.00467938\n",
            "\t10: \"Chloroflexi\" NUMERICAL mean:0.00340417 min:0 max:0.0177 sd:0.00417881\n",
            "\t11: \"Chrysiogenetes\" NUMERICAL mean:0.00321667 min:0 max:0.0177 sd:0.00348403\n",
            "\t12: \"Cyanobacteria\" NUMERICAL mean:0.0296021 min:0 max:0.306 sd:0.0599336\n",
            "\t13: \"Deferribacteres\" NUMERICAL mean:0.0232375 min:0 max:0.5779 sd:0.0916275\n",
            "\t14: \"Deinococcus.Thermus\" NUMERICAL mean:0.285138 min:0 max:13.4124 sd:1.91483\n",
            "\t15: \"Dictyoglomi\" NUMERICAL mean:0.00308125 min:0 max:0.0179 sd:0.00479377\n",
            "\t16: \"Fibrobacteres\" NUMERICAL mean:0.0002125 min:0 max:0.0021 sd:0.000519465\n",
            "\t17: \"Firmicutes\" NUMERICAL mean:58.4521 min:8.4196 max:88.6327 sd:18.5645\n",
            "\t18: \"Fusobacteria\" NUMERICAL mean:1.98121 min:0 max:18.9276 sd:4.86827\n",
            "\t19: \"Gemmatimonadetes\" NUMERICAL mean:0.0110312 min:0 max:0.1468 sd:0.0284822\n",
            "\t20: \"Kiritimatiellaeota\" NUMERICAL mean:0.000172917 min:0 max:0.0058 sd:0.000839578\n",
            "\t21: \"Nitrospirae\" NUMERICAL mean:0.00025625 min:0 max:0.0051 sd:0.000806202\n",
            "\t22: \"Planctomycetes\" NUMERICAL mean:0.0175604 min:0 max:0.1369 sd:0.0315117\n",
            "\t23: \"Proteobacteria\" NUMERICAL mean:18.7727 min:1.2588 max:61.7182 sd:14.2262\n",
            "\t24: \"Spirochaetes\" NUMERICAL mean:0.0683521 min:0 max:0.3897 sd:0.0876513\n",
            "\t25: \"Synergistetes\" NUMERICAL mean:0.0236625 min:0 max:0.4597 sd:0.0910901\n",
            "\t26: \"Tenericutes\" NUMERICAL mean:1.91021 min:0 max:36.6287 sd:6.8401\n",
            "\t27: \"Thermodesulfobacteria\" NUMERICAL mean:0.000229167 min:0 max:0.0029 sd:0.000642248\n",
            "\t28: \"Thermotogae\" NUMERICAL mean:0.00565625 min:0 max:0.0886 sd:0.0142588\n",
            "\t29: \"Verrucomicrobia\" NUMERICAL mean:0.00207917 min:0 max:0.0746 sd:0.0106434\n",
            "\t31: \"candidate.division.Zixibacteria\" NUMERICAL mean:0.00031875 min:0 max:0.0092 sd:0.00138544\n",
            "\n",
            "CATEGORICAL: 1 (3.125%)\n",
            "\t30: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO 23-12-16 19:50:00.1690 UTC kernel.cc:808] Configure learner\n",
            "[INFO 23-12-16 19:50:00.1692 UTC kernel.cc:822] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"^Acidobacteria$\"\n",
            "features: \"^Actinobacteria$\"\n",
            "features: \"^Aquificae$\"\n",
            "features: \"^Armatimonadetes$\"\n",
            "features: \"^Bacteroidetes$\"\n",
            "features: \"^Balneolaeota$\"\n",
            "features: \"^Candidatus\\\\.Bipolaricaulota$\"\n",
            "features: \"^Candidatus\\\\.Saccharibacteria$\"\n",
            "features: \"^Chlamydiae$\"\n",
            "features: \"^Chlorobi$\"\n",
            "features: \"^Chloroflexi$\"\n",
            "features: \"^Chrysiogenetes$\"\n",
            "features: \"^Cyanobacteria$\"\n",
            "features: \"^Deferribacteres$\"\n",
            "features: \"^Deinococcus\\\\.Thermus$\"\n",
            "features: \"^Dictyoglomi$\"\n",
            "features: \"^Fibrobacteres$\"\n",
            "features: \"^Firmicutes$\"\n",
            "features: \"^Fusobacteria$\"\n",
            "features: \"^Gemmatimonadetes$\"\n",
            "features: \"^Kiritimatiellaeota$\"\n",
            "features: \"^Nitrospirae$\"\n",
            "features: \"^Planctomycetes$\"\n",
            "features: \"^Proteobacteria$\"\n",
            "features: \"^Spirochaetes$\"\n",
            "features: \"^Synergistetes$\"\n",
            "features: \"^Tenericutes$\"\n",
            "features: \"^Thermodesulfobacteria$\"\n",
            "features: \"^Thermotogae$\"\n",
            "features: \"^Verrucomicrobia$\"\n",
            "features: \"^candidate\\\\.division\\\\.Zixibacteria$\"\n",
            "label: \"^__LABEL$\"\n",
            "task: CLASSIFICATION\n",
            "random_seed: 123456\n",
            "metadata {\n",
            "  framework: \"TF Keras\"\n",
            "}\n",
            "pure_serving_model: false\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 300\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    keep_non_leaf_label_distribution: true\n",
            "    num_candidate_attributes: 0\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "    uplift {\n",
            "      min_examples_in_treatment: 5\n",
            "      split_score: KULLBACK_LEIBLER\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  num_oob_variable_importances_permutations: 1\n",
            "  bootstrap_training_dataset: true\n",
            "  bootstrap_size_ratio: 1\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "  sampling_with_replacement: true\n",
            "}\n",
            "\n",
            "[INFO 23-12-16 19:50:00.1697 UTC kernel.cc:825] Deployment config:\n",
            "cache_path: \"/tmp/tmptcmxye7a/working_cache\"\n",
            "num_threads: 2\n",
            "try_resume_training: true\n",
            "\n",
            "[INFO 23-12-16 19:50:00.1698 UTC kernel.cc:887] Train model\n",
            "[INFO 23-12-16 19:50:00.1704 UTC random_forest.cc:416] Training random forest on 48 example(s) and 31 feature(s).\n",
            "[INFO 23-12-16 19:50:00.1715 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.666667 logloss:12.0146\n",
            "[INFO 23-12-16 19:50:00.1731 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.553191 logloss:5.83026\n",
            "[INFO 23-12-16 19:50:00.1742 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.6875 logloss:2.79703\n",
            "[INFO 23-12-16 19:50:00.1754 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.75 logloss:2.04507\n",
            "[INFO 23-12-16 19:50:00.1768 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.75 logloss:2.05224\n",
            "[INFO 23-12-16 19:50:00.1786 UTC random_forest.cc:802] Training of tree  51/300 (tree index:51) done accuracy:0.708333 logloss:0.711035\n",
            "[INFO 23-12-16 19:50:00.1803 UTC random_forest.cc:802] Training of tree  61/300 (tree index:47) done accuracy:0.708333 logloss:0.676551\n",
            "[INFO 23-12-16 19:50:00.1819 UTC random_forest.cc:802] Training of tree  71/300 (tree index:71) done accuracy:0.6875 logloss:0.680634\n",
            "[INFO 23-12-16 19:50:00.1831 UTC random_forest.cc:802] Training of tree  81/300 (tree index:81) done accuracy:0.6875 logloss:0.674603\n",
            "[INFO 23-12-16 19:50:00.1867 UTC random_forest.cc:802] Training of tree  91/300 (tree index:91) done accuracy:0.708333 logloss:0.670599\n",
            "[INFO 23-12-16 19:50:00.1879 UTC random_forest.cc:802] Training of tree  101/300 (tree index:101) done accuracy:0.708333 logloss:0.667445\n",
            "[INFO 23-12-16 19:50:00.1891 UTC random_forest.cc:802] Training of tree  111/300 (tree index:111) done accuracy:0.6875 logloss:0.661341\n",
            "[INFO 23-12-16 19:50:00.1961 UTC random_forest.cc:802] Training of tree  121/300 (tree index:116) done accuracy:0.666667 logloss:0.652896\n",
            "[INFO 23-12-16 19:50:00.1980 UTC random_forest.cc:802] Training of tree  131/300 (tree index:131) done accuracy:0.6875 logloss:0.653668\n",
            "[INFO 23-12-16 19:50:00.2002 UTC random_forest.cc:802] Training of tree  141/300 (tree index:141) done accuracy:0.6875 logloss:0.656325\n",
            "[INFO 23-12-16 19:50:00.2019 UTC random_forest.cc:802] Training of tree  151/300 (tree index:149) done accuracy:0.666667 logloss:0.657702\n",
            "[INFO 23-12-16 19:50:00.2029 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.666667 logloss:0.65284\n",
            "[INFO 23-12-16 19:50:00.2053 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.666667 logloss:0.648044\n",
            "[INFO 23-12-16 19:50:00.2071 UTC random_forest.cc:802] Training of tree  181/300 (tree index:181) done accuracy:0.666667 logloss:0.645498\n",
            "[INFO 23-12-16 19:50:00.2078 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.6875 logloss:0.643432\n",
            "[INFO 23-12-16 19:50:00.2119 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.6875 logloss:0.634965\n",
            "[INFO 23-12-16 19:50:00.2127 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.666667 logloss:0.638073\n",
            "[INFO 23-12-16 19:50:00.2133 UTC random_forest.cc:802] Training of tree  221/300 (tree index:219) done accuracy:0.666667 logloss:0.635776\n",
            "[INFO 23-12-16 19:50:00.2189 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.666667 logloss:0.634043\n",
            "[INFO 23-12-16 19:50:00.2197 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.666667 logloss:0.635408\n",
            "[INFO 23-12-16 19:50:00.2211 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.666667 logloss:0.635976\n",
            "[INFO 23-12-16 19:50:00.2228 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.6875 logloss:0.634321\n",
            "[INFO 23-12-16 19:50:00.2244 UTC random_forest.cc:802] Training of tree  271/300 (tree index:271) done accuracy:0.666667 logloss:0.636911\n",
            "[INFO 23-12-16 19:50:00.2264 UTC random_forest.cc:802] Training of tree  281/300 (tree index:281) done accuracy:0.666667 logloss:0.638925\n",
            "[INFO 23-12-16 19:50:00.2289 UTC random_forest.cc:802] Training of tree  291/300 (tree index:291) done accuracy:0.666667 logloss:0.639435\n",
            "[INFO 23-12-16 19:50:00.2299 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.666667 logloss:0.634107\n",
            "[INFO 23-12-16 19:50:00.2303 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.666667 logloss:0.634107\n",
            "[INFO 23-12-16 19:50:00.2315 UTC kernel.cc:919] Export model in log directory: /tmp/tmptcmxye7a with prefix df1ce4ec36304cfc\n",
            "[INFO 23-12-16 19:50:00.2357 UTC kernel.cc:937] Save model in resources\n",
            "[INFO 23-12-16 19:50:00.2427 UTC abstract_model.cc:881] Model self evaluation:\n",
            "Number of predictions (without weights): 48\n",
            "Number of predictions (with weights): 48\n",
            "Task: CLASSIFICATION\n",
            "Label: __LABEL\n",
            "\n",
            "Accuracy: 0.666667  CI95[W][0.538715 0.778485]\n",
            "LogLoss: : 0.634107\n",
            "ErrorRate: : 0.333333\n",
            "\n",
            "Default Accuracy: : 0.708333\n",
            "Default LogLoss: : 0.603637\n",
            "Default ErrorRate: : 0.291667\n",
            "\n",
            "Confusion Table:\n",
            "truth\\prediction\n",
            "    1  2\n",
            "1  31  3\n",
            "2  13  1\n",
            "Total: 48\n",
            "\n",
            "\n",
            "[INFO 23-12-16 19:50:00.2509 UTC kernel.cc:1233] Loading model from path /tmp/tmptcmxye7a/model/ with prefix df1ce4ec36304cfc\n",
            "[INFO 23-12-16 19:50:00.2556 UTC decision_forest.cc:660] Model loaded with 300 root(s), 3134 node(s), and 31 input feature(s).\n",
            "[INFO 23-12-16 19:50:00.2557 UTC abstract_model.cc:1344] Engine \"RandomForestOptPred\" built\n",
            "[INFO 23-12-16 19:50:00.2557 UTC kernel.cc:1061] Use fast generic engine\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained in 0:00:00.487677\n",
            "Compiling model...\n",
            "Model compiled.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7cc2e961e1d0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Specify the model.\n",
        "model_1 = tfdf.keras.RandomForestModel(verbose=2)\n",
        "\n",
        "# Train the model.\n",
        "model_1.fit(train_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Udtu_uS1paSu"
      },
      "source": [
        "Let's evaluate our model on the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUy4ULEMtDXB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e97b82f-4e80-4a30-c602-1b9a7d4cd01e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "loss: 0.0000\n",
            "accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "model_1.compile(metrics=[\"accuracy\"])\n",
        "evaluation = model_1.evaluate(test_ds, return_dict=True)\n",
        "\n",
        "for name, value in evaluation.items():\n",
        "  print(f\"{name}: {value:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHBFtUeElRYz"
      },
      "source": [
        "## Prepare this model for TensorFlow Serving."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbC4lmgfr5Sm"
      },
      "source": [
        "Export the model to the SavedModel format for later re-use e.g.\n",
        "[TensorFlow Serving](https://www.tensorflow.org/tfx/guide/serving).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08YWGr9U2fza",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8c1fb8e-f02b-4f76-ee10-b950be060666"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`Candidatus.Bipolaricaulota` is not a valid tf.function parameter name. Sanitizing to `Candidatus_Bipolaricaulota`.\n",
            "WARNING:absl:`Candidatus.Saccharibacteria` is not a valid tf.function parameter name. Sanitizing to `Candidatus_Saccharibacteria`.\n",
            "WARNING:absl:`Deinococcus.Thermus` is not a valid tf.function parameter name. Sanitizing to `Deinococcus_Thermus`.\n",
            "WARNING:absl:`candidate.division.Zixibacteria` is not a valid tf.function parameter name. Sanitizing to `candidate_division_Zixibacteria`.\n",
            "WARNING:absl:`Candidatus.Bipolaricaulota` is not a valid tf.function parameter name. Sanitizing to `Candidatus_Bipolaricaulota`.\n"
          ]
        }
      ],
      "source": [
        "model_1.save(\"/tmp/my_saved_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUIxf8N6Yjl0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "2b2fe61b-8091-4116-e1a0-06a22f28fdf3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<script src=\"https://d3js.org/d3.v6.min.js\"></script>\n",
              "<div id=\"tree_plot_73a45b1c390d415182e8bffd49bb6e56\"></div>\n",
              "<script>\n",
              "/*\n",
              " * Copyright 2021 Google LLC.\n",
              " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              " * you may not use this file except in compliance with the License.\n",
              " * You may obtain a copy of the License at\n",
              " *\n",
              " *     https://www.apache.org/licenses/LICENSE-2.0\n",
              " *\n",
              " * Unless required by applicable law or agreed to in writing, software\n",
              " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              " * See the License for the specific language governing permissions and\n",
              " * limitations under the License.\n",
              " */\n",
              "\n",
              "/**\n",
              " *  Plotting of decision trees generated by TF-DF.\n",
              " *\n",
              " *  A tree is a recursive structure of node objects.\n",
              " *  A node contains one or more of the following components:\n",
              " *\n",
              " *    - A value: Representing the output of the node. If the node is not a leaf,\n",
              " *      the value is only present for analysis i.e. it is not used for\n",
              " *      predictions.\n",
              " *\n",
              " *    - A condition : For non-leaf nodes, the condition (also known as split)\n",
              " *      defines a binary test to branch to the positive or negative child.\n",
              " *\n",
              " *    - An explanation: Generally a plot showing the relation between the label\n",
              " *      and the condition to give insights about the effect of the condition.\n",
              " *\n",
              " *    - Two children : For non-leaf nodes, the children nodes. The first\n",
              " *      children (i.e. \"node.children[0]\") is the negative children (drawn in\n",
              " *      red). The second children is the positive one (drawn in green).\n",
              " *\n",
              " */\n",
              "\n",
              "/**\n",
              " * Plots a single decision tree into a DOM element.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!tree} raw_tree Recursive tree structure.\n",
              " * @param {string} canvas_id Id of the output dom element.\n",
              " */\n",
              "function display_tree(options, raw_tree, canvas_id) {\n",
              "  console.log(options);\n",
              "\n",
              "  // Determine the node placement.\n",
              "  const tree_struct = d3.tree().nodeSize(\n",
              "      [options.node_y_offset, options.node_x_offset])(d3.hierarchy(raw_tree));\n",
              "\n",
              "  // Boundaries of the node placement.\n",
              "  let x_min = Infinity;\n",
              "  let x_max = -x_min;\n",
              "  let y_min = Infinity;\n",
              "  let y_max = -x_min;\n",
              "\n",
              "  tree_struct.each(d => {\n",
              "    if (d.x > x_max) x_max = d.x;\n",
              "    if (d.x < x_min) x_min = d.x;\n",
              "    if (d.y > y_max) y_max = d.y;\n",
              "    if (d.y < y_min) y_min = d.y;\n",
              "  });\n",
              "\n",
              "  // Size of the plot.\n",
              "  const width = y_max - y_min + options.node_x_size + options.margin * 2;\n",
              "  const height = x_max - x_min + options.node_y_size + options.margin * 2 +\n",
              "      options.node_y_offset - options.node_y_size;\n",
              "\n",
              "  const plot = d3.select(canvas_id);\n",
              "\n",
              "  // Tool tip\n",
              "  options.tooltip = plot.append('div')\n",
              "                        .attr('width', 100)\n",
              "                        .attr('height', 100)\n",
              "                        .style('padding', '4px')\n",
              "                        .style('background', '#fff')\n",
              "                        .style('box-shadow', '4px 4px 0px rgba(0,0,0,0.1)')\n",
              "                        .style('border', '1px solid black')\n",
              "                        .style('font-family', 'sans-serif')\n",
              "                        .style('font-size', options.font_size)\n",
              "                        .style('position', 'absolute')\n",
              "                        .style('z-index', '10')\n",
              "                        .attr('pointer-events', 'none')\n",
              "                        .style('display', 'none');\n",
              "\n",
              "  // Create canvas\n",
              "  const svg = plot.append('svg').attr('width', width).attr('height', height);\n",
              "  const graph =\n",
              "      svg.style('overflow', 'visible')\n",
              "          .append('g')\n",
              "          .attr('font-family', 'sans-serif')\n",
              "          .attr('font-size', options.font_size)\n",
              "          .attr(\n",
              "              'transform',\n",
              "              () => `translate(${options.margin},${\n",
              "                  - x_min + options.node_y_offset / 2 + options.margin})`);\n",
              "\n",
              "  // Plot bounding box.\n",
              "  if (options.show_plot_bounding_box) {\n",
              "    svg.append('rect')\n",
              "        .attr('width', width)\n",
              "        .attr('height', height)\n",
              "        .attr('fill', 'none')\n",
              "        .attr('stroke-width', 1.0)\n",
              "        .attr('stroke', 'black');\n",
              "  }\n",
              "\n",
              "  // Draw the edges.\n",
              "  display_edges(options, graph, tree_struct);\n",
              "\n",
              "  // Draw the nodes.\n",
              "  display_nodes(options, graph, tree_struct);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Draw the nodes of the tree.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!graph} graph D3 search handle containing the graph.\n",
              " * @param {!tree_struct} tree_struct Structure of the tree (node placement,\n",
              " *     data, etc.).\n",
              " */\n",
              "function display_nodes(options, graph, tree_struct) {\n",
              "  const nodes = graph.append('g')\n",
              "                    .selectAll('g')\n",
              "                    .data(tree_struct.descendants())\n",
              "                    .join('g')\n",
              "                    .attr('transform', d => `translate(${d.y},${d.x})`);\n",
              "\n",
              "  nodes.append('rect')\n",
              "      .attr('x', 0.5)\n",
              "      .attr('y', 0.5)\n",
              "      .attr('width', options.node_x_size)\n",
              "      .attr('height', options.node_y_size)\n",
              "      .attr('stroke', 'lightgrey')\n",
              "      .attr('stroke-width', 1)\n",
              "      .attr('fill', 'white')\n",
              "      .attr('y', -options.node_y_size / 2);\n",
              "\n",
              "  // Brackets on the right of condition nodes without children.\n",
              "  non_leaf_node_without_children =\n",
              "      nodes.filter(node => node.data.condition != null && node.children == null)\n",
              "          .append('g')\n",
              "          .attr('transform', `translate(${options.node_x_size},0)`);\n",
              "\n",
              "  non_leaf_node_without_children.append('path')\n",
              "      .attr('d', 'M0,0 C 10,0 0,10 10,10')\n",
              "      .attr('fill', 'none')\n",
              "      .attr('stroke-width', 1.0)\n",
              "      .attr('stroke', '#F00');\n",
              "\n",
              "  non_leaf_node_without_children.append('path')\n",
              "      .attr('d', 'M0,0 C 10,0 0,-10 10,-10')\n",
              "      .attr('fill', 'none')\n",
              "      .attr('stroke-width', 1.0)\n",
              "      .attr('stroke', '#0F0');\n",
              "\n",
              "  const node_content = nodes.append('g').attr(\n",
              "      'transform',\n",
              "      `translate(0,${options.node_padding - options.node_y_size / 2})`);\n",
              "\n",
              "  node_content.append(node => create_node_element(options, node));\n",
              "}\n",
              "\n",
              "/**\n",
              " * Creates the D3 content for a single node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!node} node Node to draw.\n",
              " * @return {!d3} D3 content.\n",
              " */\n",
              "function create_node_element(options, node) {\n",
              "  // Output accumulator.\n",
              "  let output = {\n",
              "    // Content to draw.\n",
              "    content: d3.create('svg:g'),\n",
              "    // Vertical offset to the next element to draw.\n",
              "    vertical_offset: 0\n",
              "  };\n",
              "\n",
              "  // Conditions.\n",
              "  if (node.data.condition != null) {\n",
              "    display_condition(options, node.data.condition, output);\n",
              "  }\n",
              "\n",
              "  // Values.\n",
              "  if (node.data.value != null) {\n",
              "    display_value(options, node.data.value, output);\n",
              "  }\n",
              "\n",
              "  // Explanations.\n",
              "  if (node.data.explanation != null) {\n",
              "    display_explanation(options, node.data.explanation, output);\n",
              "  }\n",
              "\n",
              "  return output.content.node();\n",
              "}\n",
              "\n",
              "\n",
              "/**\n",
              " * Adds a single line of text inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {string} text Text to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_node_text(options, text, output) {\n",
              "  output.content.append('text')\n",
              "      .attr('x', options.node_padding)\n",
              "      .attr('y', output.vertical_offset)\n",
              "      .attr('alignment-baseline', 'hanging')\n",
              "      .text(text);\n",
              "  output.vertical_offset += 10;\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a single line of text inside of a node with a tooltip.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {string} text Text to display.\n",
              " * @param {string} tooltip Text in the Tooltip.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_node_text_with_tooltip(options, text, tooltip, output) {\n",
              "  const item = output.content.append('text')\n",
              "                   .attr('x', options.node_padding)\n",
              "                   .attr('alignment-baseline', 'hanging')\n",
              "                   .text(text);\n",
              "\n",
              "  add_tooltip(options, item, () => tooltip);\n",
              "  output.vertical_offset += 10;\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a tooltip to a dom element.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!dom} target Dom element to equip with a tooltip.\n",
              " * @param {!func} get_content Generates the html content of the tooltip.\n",
              " */\n",
              "function add_tooltip(options, target, get_content) {\n",
              "  function show(d) {\n",
              "    options.tooltip.style('display', 'block');\n",
              "    options.tooltip.html(get_content());\n",
              "  }\n",
              "\n",
              "  function hide(d) {\n",
              "    options.tooltip.style('display', 'none');\n",
              "  }\n",
              "\n",
              "  function move(d) {\n",
              "    options.tooltip.style('display', 'block');\n",
              "    options.tooltip.style('left', (d.pageX + 5) + 'px');\n",
              "    options.tooltip.style('top', d.pageY + 'px');\n",
              "  }\n",
              "\n",
              "  target.on('mouseover', show);\n",
              "  target.on('mouseout', hide);\n",
              "  target.on('mousemove', move);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a condition inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!condition} condition Condition to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_condition(options, condition, output) {\n",
              "  threshold_format = d3.format('r');\n",
              "\n",
              "  if (condition.type === 'IS_MISSING') {\n",
              "    display_node_text(options, `${condition.attribute} is missing`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'IS_TRUE') {\n",
              "    display_node_text(options, `${condition.attribute} is true`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'NUMERICAL_IS_HIGHER_THAN') {\n",
              "    format = d3.format('r');\n",
              "    display_node_text(\n",
              "        options,\n",
              "        `${condition.attribute} >= ${threshold_format(condition.threshold)}`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'CATEGORICAL_IS_IN') {\n",
              "    display_node_text_with_tooltip(\n",
              "        options, `${condition.attribute} in [...]`,\n",
              "        `${condition.attribute} in [${condition.mask}]`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'CATEGORICAL_SET_CONTAINS') {\n",
              "    display_node_text_with_tooltip(\n",
              "        options, `${condition.attribute} intersect [...]`,\n",
              "        `${condition.attribute} intersect [${condition.mask}]`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'NUMERICAL_SPARSE_OBLIQUE') {\n",
              "    display_node_text_with_tooltip(\n",
              "        options, `Sparse oblique split...`,\n",
              "        `[${condition.attributes}]*[${condition.weights}]>=${\n",
              "            threshold_format(condition.threshold)}`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  display_node_text(\n",
              "      options, `Non supported condition ${condition.type}`, output);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a value inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!value} value Value to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_value(options, value, output) {\n",
              "  if (value.type === 'PROBABILITY') {\n",
              "    const left_margin = 0;\n",
              "    const right_margin = 50;\n",
              "    const plot_width = options.node_x_size - options.node_padding * 2 -\n",
              "        left_margin - right_margin;\n",
              "\n",
              "    let cusum = Array.from(d3.cumsum(value.distribution));\n",
              "    cusum.unshift(0);\n",
              "    const distribution_plot = output.content.append('g').attr(\n",
              "        'transform', `translate(0,${output.vertical_offset + 0.5})`);\n",
              "\n",
              "    distribution_plot.selectAll('rect')\n",
              "        .data(value.distribution)\n",
              "        .join('rect')\n",
              "        .attr('height', 10)\n",
              "        .attr(\n",
              "            'x',\n",
              "            (d, i) =>\n",
              "                (cusum[i] * plot_width + left_margin + options.node_padding))\n",
              "        .attr('width', (d, i) => d * plot_width)\n",
              "        .style('fill', (d, i) => d3.schemeSet1[i]);\n",
              "\n",
              "    const num_examples =\n",
              "        output.content.append('g')\n",
              "            .attr('transform', `translate(0,${output.vertical_offset})`)\n",
              "            .append('text')\n",
              "            .attr('x', options.node_x_size - options.node_padding)\n",
              "            .attr('alignment-baseline', 'hanging')\n",
              "            .attr('text-anchor', 'end')\n",
              "            .text(`(${value.num_examples})`);\n",
              "\n",
              "    const distribution_details = d3.create('ul');\n",
              "    distribution_details.selectAll('li')\n",
              "        .data(value.distribution)\n",
              "        .join('li')\n",
              "        .append('span')\n",
              "        .text(\n",
              "            (d, i) =>\n",
              "                'class ' + i + ': ' + d3.format('.3%')(value.distribution[i]));\n",
              "\n",
              "    add_tooltip(options, distribution_plot, () => distribution_details.html());\n",
              "    add_tooltip(options, num_examples, () => 'Number of examples');\n",
              "\n",
              "    output.vertical_offset += 10;\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (value.type === 'REGRESSION') {\n",
              "    display_node_text(\n",
              "        options,\n",
              "        'value: ' + d3.format('r')(value.value) + ` (` +\n",
              "            d3.format('.6')(value.num_examples) + `)`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (value.type === 'UPLIFT') {\n",
              "    display_node_text(\n",
              "        options,\n",
              "        'effect: ' + d3.format('r')(value.treatment_effect) + ` (` +\n",
              "            d3.format('.6')(value.num_examples) + `)`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  display_node_text(options, `Non supported value ${value.type}`, output);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds an explanation inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!explanation} explanation Explanation to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_explanation(options, explanation, output) {\n",
              "  // Margin before the explanation.\n",
              "  output.vertical_offset += 10;\n",
              "\n",
              "  display_node_text(\n",
              "      options, `Non supported explanation ${explanation.type}`, output);\n",
              "}\n",
              "\n",
              "\n",
              "/**\n",
              " * Draw the edges of the tree.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!graph} graph D3 search handle containing the graph.\n",
              " * @param {!tree_struct} tree_struct Structure of the tree (node placement,\n",
              " *     data, etc.).\n",
              " */\n",
              "function display_edges(options, graph, tree_struct) {\n",
              "  // Draw an edge between a parent and a child node with a bezier.\n",
              "  function draw_single_edge(d) {\n",
              "    return 'M' + (d.source.y + options.node_x_size) + ',' + d.source.x + ' C' +\n",
              "        (d.source.y + options.node_x_size + options.edge_rounding) + ',' +\n",
              "        d.source.x + ' ' + (d.target.y - options.edge_rounding) + ',' +\n",
              "        d.target.x + ' ' + d.target.y + ',' + d.target.x;\n",
              "  }\n",
              "\n",
              "  graph.append('g')\n",
              "      .attr('fill', 'none')\n",
              "      .attr('stroke-width', 1.2)\n",
              "      .selectAll('path')\n",
              "      .data(tree_struct.links())\n",
              "      .join('path')\n",
              "      .attr('d', draw_single_edge)\n",
              "      .attr(\n",
              "          'stroke', d => (d.target === d.source.children[0]) ? '#0F0' : '#F00');\n",
              "}\n",
              "\n",
              "display_tree({\"margin\": 10, \"node_x_size\": 160, \"node_y_size\": 28, \"node_x_offset\": 180, \"node_y_offset\": 33, \"font_size\": 10, \"edge_rounding\": 20, \"node_padding\": 2, \"show_plot_bounding_box\": false}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.75, 0.25], \"num_examples\": 48.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"Dictyoglomi\", \"threshold\": 0.006149999797344208}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.36363636363636365, 0.6363636363636364], \"num_examples\": 11.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"Dictyoglomi\", \"threshold\": 0.00795000046491623}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.8, 0.2], \"num_examples\": 5.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0, 1.0], \"num_examples\": 6.0}}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.8648648648648649, 0.13513513513513514], \"num_examples\": 37.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"Chlorobi\", \"threshold\": 0.0002500000118743628}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [1.0, 0.0], \"num_examples\": 17.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.75, 0.25], \"num_examples\": 20.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"Firmicutes\", \"threshold\": 61.309852600097656}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.375, 0.625], \"num_examples\": 8.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [1.0, 0.0], \"num_examples\": 12.0}}]}]}]}, \"#tree_plot_73a45b1c390d415182e8bffd49bb6e56\")\n",
              "</script>\n"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "tfdf.model_plotter.plot_model_in_colab(model_1, tree_idx=0, max_depth=3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.make_inspector().evaluation()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JE_PanV22EZ",
        "outputId": "a4be45fa-e3e9-4301-8d4f-6b19b9400d39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Evaluation(num_examples=48, accuracy=0.6666666666666666, loss=0.6341070346534252, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}